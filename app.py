import streamlit as st
import pandas as pd
import numpy as np
import pickle
import plotly.graph_objects as go
import plotly.express as px
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Detecci√≥n de Ataques de Red",
    page_icon="üõ°Ô∏è",
    layout="wide"
)

# T√≠tulo principal
st.title("üõ°Ô∏è Sistema de Detecci√≥n de Ataques de Red")
st.markdown("### Proyecto de Ciberseguridad con Machine Learning")
st.markdown("---")

# Cargar modelo y transformadores
@st.cache_resource
def load_model():
    model = pickle.load(open('data/processed/best_model.pkl', 'rb'))
    scaler = pickle.load(open('data/processed/scaler.pkl', 'rb'))
    encoders = pickle.load(open('data/processed/label_encoders.pkl', 'rb'))
    return model, scaler, encoders

try:
    model, scaler, encoders = load_model()
    st.success("‚úÖ Modelo cargado correctamente")
except Exception as e:
    st.error(f"‚ùå Error al cargar el modelo: {e}")
    st.stop()

# Sidebar con informaci√≥n del proyecto
st.sidebar.header("üìä Informaci√≥n del Proyecto")
st.sidebar.markdown("""
**Dataset:** NSL-KDD

**Modelo:** Random Forest Classifier

**M√©tricas del modelo:**
- Accuracy: ~96.87%
- Precision: ~95.98%
- Recall: ~97.21%
- F1-Score: ~96.59%

**Categor√≠as de ataques:**
- DoS (Denial of Service)
- Probe (Escaneo de red)
- R2L (Remote to Local)
- U2R (User to Root)
""")

# Tabs principales
tab1, tab2, tab3 = st.tabs(["üîç Predicci√≥n", "üìà An√°lisis del Modelo", "üìö Acerca del Proyecto"])

# TAB 1: Predicci√≥n
with tab1:
    st.header("Predicci√≥n de Conexiones de Red")
    
    # Subsecci√≥n: Predicci√≥n con ejemplos reales
    st.subheader("üéØ Prueba con Ejemplos Reales del Dataset")
    st.markdown("Usa ejemplos completos del dataset de prueba con todas las features:")
    
    # Cargar datos de test
    try:
        X_test_full = pd.read_csv('data/processed/X_test.csv')
        y_test_full = pd.read_csv('data/processed/y_test.csv').values.ravel()
        
        col_ex1, col_ex2, col_ex3 = st.columns(3)
        
        with col_ex1:
            if st.button("üìò Ejemplo: Conexi√≥n Normal", use_container_width=True):
                # Buscar un ejemplo normal del dataset
                normal_indices = np.where(y_test_full == 0)[0]
                normal_idx = normal_indices[0]
                example = X_test_full.iloc[normal_idx:normal_idx+1]
                
                prediction = model.predict(example)[0]
                proba = model.predict_proba(example)[0]
                
                st.markdown("---")
                st.write("**Caracter√≠sticas principales:**")
                st.write(f"- src_bytes: {example['src_bytes'].values[0]:.0f}")
                st.write(f"- dst_bytes: {example['dst_bytes'].values[0]:.0f}")
                st.write(f"- count: {example['count'].values[0]:.0f}")
                st.write(f"- serror_rate: {example['serror_rate'].values[0]:.2f}")
                
                st.markdown("**Resultado:**")
                if prediction == 0:
                    st.success(f"‚úÖ **CONEXI√ìN NORMAL** - Confianza: {proba[0]*100:.2f}%")
                else:
                    st.error(f"‚ùå **Falso Positivo** - Predicho como ataque con {proba[1]*100:.2f}%")
        
        with col_ex2:
            if st.button("üî¥ Ejemplo: Ataque DoS/Probe", use_container_width=True):
                # Buscar un ataque del dataset
                attack_indices = np.where(y_test_full == 1)[0]
                attack_idx = attack_indices[10]  # Usar el √≠ndice 10 para variedad
                example = X_test_full.iloc[attack_idx:attack_idx+1]
                
                prediction = model.predict(example)[0]
                proba = model.predict_proba(example)[0]
                
                st.markdown("---")
                st.write("**Caracter√≠sticas principales:**")
                st.write(f"- src_bytes: {example['src_bytes'].values[0]:.0f}")
                st.write(f"- dst_bytes: {example['dst_bytes'].values[0]:.0f}")
                st.write(f"- count: {example['count'].values[0]:.0f}")
                st.write(f"- serror_rate: {example['serror_rate'].values[0]:.2f}")
                
                st.markdown("**Resultado:**")
                if prediction == 1:
                    st.error(f"üö® **ATAQUE DETECTADO** - Confianza: {proba[1]*100:.2f}%")
                else:
                    st.warning(f"‚ö†Ô∏è **Falso Negativo** - No detectado ({proba[0]*100:.2f}% normal)")
        
        with col_ex3:
            if st.button("üîç Ejemplo Aleatorio", use_container_width=True):
                # Ejemplo aleatorio
                random_idx = np.random.randint(0, len(X_test_full))
                example = X_test_full.iloc[random_idx:random_idx+1]
                real_label = y_test_full[random_idx]
                
                prediction = model.predict(example)[0]
                proba = model.predict_proba(example)[0]
                
                st.markdown("---")
                st.write(f"**Etiqueta real:** {'üö® Ataque' if real_label == 1 else '‚úÖ Normal'}")
                st.write(f"**Predicci√≥n:** {'üö® Ataque' if prediction == 1 else '‚úÖ Normal'}")
                st.write(f"**Confianza:** {max(proba)*100:.2f}%")
                
                st.write("**Caracter√≠sticas principales:**")
                st.write(f"- src_bytes: {example['src_bytes'].values[0]:.0f}")
                st.write(f"- dst_bytes: {example['dst_bytes'].values[0]:.0f}")
                st.write(f"- count: {example['count'].values[0]:.0f}")
                
                if prediction == real_label:
                    st.success("‚úÖ Predicci√≥n correcta")
                else:
                    st.error("‚ùå Predicci√≥n incorrecta")
    
    except Exception as e:
        st.error(f"Error al cargar ejemplos: {e}")
    
    st.markdown("---")
    
    # Subsecci√≥n: Predicci√≥n manual
    st.subheader("‚úçÔ∏è Predicci√≥n Manual (Entrada de Datos)")
    st.markdown("‚ö†Ô∏è **Nota:** Solo se ingresan 13 de 41 features. El resto usa valores por defecto.")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Informaci√≥n de Conexi√≥n**")
        duration = st.number_input("Duration (segundos)", min_value=0, value=0)
        protocol_type = st.selectbox("Protocol Type", ["tcp", "udp", "icmp"])
        service = st.selectbox("Service", ["http", "ftp", "smtp", "ssh", "telnet", "other"])
        flag = st.selectbox("Flag", ["SF", "S0", "REJ", "RSTR", "SH", "S1", "S2", "RSTOS0", "RSTO", "S3", "OTH"])
    
    with col2:
        st.markdown("**Volumen de Datos**")
        src_bytes = st.number_input("Source Bytes", min_value=0, value=0)
        dst_bytes = st.number_input("Destination Bytes", min_value=0, value=0)
        land = st.selectbox("Land", [0, 1])
        wrong_fragment = st.number_input("Wrong Fragment", min_value=0, value=0)
        urgent = st.number_input("Urgent", min_value=0, value=0)
    
    with col3:
        st.markdown("**Caracter√≠sticas de Conexi√≥n**")
        count = st.number_input("Count", min_value=0, value=0, help="Conexiones al mismo host en 2 segundos")
        srv_count = st.number_input("Srv Count", min_value=0, value=0)
        serror_rate = st.slider("SError Rate", 0.0, 1.0, 0.0)
        rerror_rate = st.slider("RError Rate", 0.0, 1.0, 0.0)
    
    # Bot√≥n de predicci√≥n manual
    if st.button("üîç Analizar Conexi√≥n Manual", type="primary"):
        try:
            # Cargar las columnas originales del entrenamiento
            X_train_sample = pd.read_csv('data/processed/X_train.csv', nrows=1)
            
            # Crear DataFrame con TODAS las columnas en el MISMO ORDEN
            input_data = {}
            
            # Llenar con los valores ingresados por el usuario
            user_inputs = {
                'duration': duration,
                'protocol_type': protocol_type,
                'service': service,
                'flag': flag,
                'src_bytes': src_bytes,
                'dst_bytes': dst_bytes,
                'land': land,
                'wrong_fragment': wrong_fragment,
                'urgent': urgent,
                'count': count,
                'srv_count': srv_count,
                'serror_rate': serror_rate,
                'rerror_rate': rerror_rate
            }
            
            # Valores por defecto para features no ingresadas
            default_values = {
                'hot': 0,
                'num_failed_logins': 0,
                'logged_in': 1,
                'num_compromised': 0,
                'root_shell': 0,
                'su_attempted': 0,
                'num_root': 0,
                'num_file_creations': 0,
                'num_shells': 0,
                'num_access_files': 0,
                'num_outbound_cmds': 0,
                'is_host_login': 0,
                'is_guest_login': 0,
                'srv_serror_rate': 0.0,
                'srv_rerror_rate': 0.0,
                'same_srv_rate': 1.0,
                'diff_srv_rate': 0.0,
                'srv_diff_host_rate': 0.0,
                'dst_host_count': 255,
                'dst_host_srv_count': 255,
                'dst_host_same_srv_rate': 1.0,
                'dst_host_diff_srv_rate': 0.0,
                'dst_host_same_src_port_rate': 1.0,
                'dst_host_srv_diff_host_rate': 0.0,
                'dst_host_serror_rate': 0.0,
                'dst_host_srv_serror_rate': 0.0,
                'dst_host_rerror_rate': 0.0,
                'dst_host_srv_rerror_rate': 0.0
            }
            
            # Crear DataFrame con el orden correcto de columnas
            for col in X_train_sample.columns:
                if col in user_inputs:
                    input_data[col] = user_inputs[col]
                elif col in default_values:
                    input_data[col] = default_values[col]
                else:
                    input_data[col] = 0
            
            df_input = pd.DataFrame([input_data])
            
            # Aplicar encoding a variables categ√≥ricas
            categorical_cols = ['protocol_type', 'service', 'flag']
            for col in categorical_cols:
                if col in encoders and col in df_input.columns:
                    try:
                        # Manejar valores no vistos durante entrenamiento
                        if df_input[col].values[0] not in encoders[col].classes_:
                            # Usar la clase m√°s com√∫n como fallback
                            df_input[col] = encoders[col].classes_[0]
                        df_input[col] = encoders[col].transform(df_input[col])
                    except Exception as e:
                        st.warning(f"Advertencia en encoding de {col}: {e}")
                        df_input[col] = 0
            
            # Asegurar que todas las columnas son num√©ricas
            df_input = df_input.astype(float)
            
            # Verificar orden de columnas
            df_input = df_input[X_train_sample.columns]
            
            # Hacer predicci√≥n
            prediction = model.predict(df_input)[0]
            proba = model.predict_proba(df_input)[0]
            
            # Mostrar resultado
            st.markdown("---")
            col_res1, col_res2, col_res3 = st.columns(3)
            
            with col_res1:
                if prediction == 0:
                    st.success("### ‚úÖ CONEXI√ìN NORMAL")
                    st.metric("Clasificaci√≥n", "Normal", delta="Seguro")
                else:
                    st.error("### üö® ATAQUE DETECTADO")
                    st.metric("Clasificaci√≥n", "Ataque", delta="Peligro", delta_color="inverse")
            
            with col_res2:
                st.metric("Probabilidad Normal", f"{proba[0]*100:.2f}%")
                st.metric("Probabilidad Ataque", f"{proba[1]*100:.2f}%")
            
            with col_res3:
                confidence = max(proba) * 100
                st.metric("Confianza del Modelo", f"{confidence:.2f}%")
                
                if confidence > 90:
                    st.info("üéØ Alta confianza")
                elif confidence > 70:
                    st.warning("‚ö†Ô∏è Confianza moderada")
                else:
                    st.error("‚ùó Baja confianza - requiere revisi√≥n manual")
        
        except Exception as e:
            st.error(f"Error al hacer la predicci√≥n: {e}")

# TAB 2: An√°lisis del Modelo
with tab2:
    st.header("An√°lisis del Rendimiento del Modelo")
    
    # Cargar datos de test para mostrar m√©tricas
    try:
        X_test = pd.read_csv('data/processed/X_test.csv')
        y_test = pd.read_csv('data/processed/y_test.csv').values.ravel()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìä M√©tricas Principales")
            
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            y_pred = model.predict(X_test)
            
            metrics_data = {
                'M√©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
                'Valor': [
                    accuracy_score(y_test, y_pred),
                    precision_score(y_test, y_pred),
                    recall_score(y_test, y_pred),
                    f1_score(y_test, y_pred)
                ]
            }
            
            df_metrics = pd.DataFrame(metrics_data)
            df_metrics['Porcentaje'] = (df_metrics['Valor'] * 100).apply(lambda x: f"{x:.2f}%")
            df_metrics['Valor'] = df_metrics['Valor'].apply(lambda x: f"{x:.4f}")
            
            st.dataframe(df_metrics, hide_index=True, use_container_width=True)
            
            # Explicaci√≥n de m√©tricas
            st.markdown("""
            **Interpretaci√≥n:**
            - **Accuracy**: % de predicciones correctas totales
            - **Precision**: De los predichos como ataque, % que s√≠ lo eran
            - **Recall**: De los ataques reales, % que detectamos
            - **F1-Score**: Balance entre Precision y Recall
            """)
        
        with col2:
            st.subheader("üéØ Matriz de Confusi√≥n")
            
            from sklearn.metrics import confusion_matrix
            cm = confusion_matrix(y_test, y_pred)
            
            fig = go.Figure(data=go.Heatmap(
                z=cm,
                x=['Normal', 'Ataque'],
                y=['Normal', 'Ataque'],
                colorscale='Blues',
                text=cm,
                texttemplate='%{text}',
                textfont={"size": 20},
                hovertemplate='Real: %{y}<br>Predicci√≥n: %{x}<br>Cantidad: %{z}<extra></extra>'
            ))
            
            fig.update_layout(
                title='Matriz de Confusi√≥n',
                xaxis_title='Predicci√≥n',
                yaxis_title='Real',
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Desglose de la matriz
            st.markdown(f"""
            **Resultados:**
            - ‚úÖ True Negatives (TN): {cm[0,0]:,}
            - ‚ùå False Positives (FP): {cm[0,1]:,}
            - ‚ùå False Negatives (FN): {cm[1,0]:,}
            - ‚úÖ True Positives (TP): {cm[1,1]:,}
            """)
        
        # Feature Importance
        st.markdown("---")
        st.subheader("üîç Importancia de Features")
        
        feature_importance = pd.DataFrame({
            'Feature': X_test.columns,
            'Importance': model.feature_importances_
        }).sort_values('Importance', ascending=False).head(15)
        
        fig = px.bar(
            feature_importance,
            x='Importance',
            y='Feature',
            orientation='h',
            title='Top 15 Features M√°s Importantes',
            color='Importance',
            color_continuous_scale='Viridis'
        )
        
        fig.update_layout(height=500, yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig, use_container_width=True)
        
        # Mostrar tabla
        st.dataframe(
            feature_importance.reset_index(drop=True),
            use_container_width=True
        )
        
    except Exception as e:
        st.error(f"Error al cargar datos de an√°lisis: {e}")

# TAB 3: Acerca del Proyecto
with tab3:
    st.header("üìö Acerca del Proyecto")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üéØ Objetivo
        Desarrollar un sistema de detecci√≥n de intrusiones en redes usando Machine Learning 
        para identificar conexiones maliciosas en tiempo real.
        
        ### üóÇÔ∏è Dataset
        **NSL-KDD** - Versi√≥n mejorada del dataset KDD Cup 1999
        - 125,973 registros de entrenamiento
        - 22,544 registros de prueba
        - 41 features por conexi√≥n
        - 5 categor√≠as: Normal, DoS, Probe, R2L, U2R
        
        ### ü§ñ Modelos Entrenados
        1. **Logistic Regression** (Baseline)
        2. **Decision Tree**
        3. **Random Forest** ‚≠ê (Mejor modelo)
        
        ### üìä Pipeline del Proyecto
        1. An√°lisis Exploratorio de Datos (EDA)
        2. Preprocesamiento (Encoding, Normalizaci√≥n)
        3. Entrenamiento de Modelos
        4. Evaluaci√≥n y Comparaci√≥n
        5. Despliegue del Dashboard
        """)
    
    with col2:
        st.markdown("""
        ### üõ†Ô∏è Tecnolog√≠as Utilizadas
        - **Python 3.x**
        - **Pandas & NumPy** - Manipulaci√≥n de datos
        - **Scikit-learn** - Machine Learning
        - **Streamlit** - Dashboard interactivo
        - **Plotly** - Visualizaciones interactivas
        
        ### üìà Resultados Clave
        - **Accuracy**: 96.87%
        - **Precision**: 95.98%
        - **Recall**: 97.21%
        - **F1-Score**: 96.59%
        
        ### üîë Features M√°s Importantes
        1. src_bytes - Bytes enviados
        2. dst_bytes - Bytes recibidos
        3. count - Conexiones en 2 segundos
        
        ### üë®‚Äçüíª Desarrollador
        **[Leslie Jimenez]**  
        Proyecto de portafolio - Data Science Junior  
        Especializaci√≥n: Ciberseguridad & ML
        
        ### üìû Contacto
        - GitHub: [DomiAndi](https://github.com/DomiAndi)
        - LinkedIn: [leslie-jimenez-navarrete](https://linkedin.com/in/leslie-jimenez-navarrete-a4670a1ba/)
        - Email: tu-email@ejemplo.com
        """)
    
    st.markdown("---")
    
    st.markdown("""
    ### üìù Notas Importantes
    
    **Limitaciones:**
    - La predicci√≥n manual usa solo 13 de 41 features, el resto se rellena con valores por defecto
    - Para mejores resultados en producci√≥n, se necesitar√≠an todas las features del tr√°fico de red
    - El modelo fue entrenado con datos del a√±o 1999, patrones de ataques actuales pueden diferir
    
    **Mejoras Futuras:**
    - Integraci√≥n con sistemas de monitoreo en tiempo real
    - Actualizaci√≥n del modelo con datasets m√°s recientes
    - Detecci√≥n de tipos espec√≠ficos de ataques (no solo binario)
    - Implementaci√≥n de t√©cnicas de balanceo de clases avanzadas
    """)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>üõ°Ô∏è Sistema de Detecci√≥n de Ataques de Red | Desarrollado con ‚ù§Ô∏è usando Python & Streamlit</p>
</div>
""", unsafe_allow_html=True)
